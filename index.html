<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8"/>
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1">

    <meta name="keywords" content="machine learning, deep learning, self-supervised learning">

    <title>ICPR22-SSL</title>
    <meta name="description" content="Theories, Applications, and Cross Modality for Self-Supervised Learning Models">

    <!-- CSS  -->
    <link rel="stylesheet" type="text/css" href="./static/css/bootstrap.min.css">
    <link rel="stylesheet" type="text/css" href="./static/css/main.183a8f.css" media="screen,projection">
  </head>

  <body>

    <!-- <div class="top-strip"></div> -->
    <div class="navbar navbar-default navbar-fixed-top">
      <div class="container">
        <div class="navbar-header">
          <a class="navbar-brand" href="/">ICPR22 SSL</a>
          <button class="navbar-toggle" type="button" data-toggle="collapse" data-target="#navbar-main">
            <span class="icon-bar"></span>
            <span class="icon-bar"></span>
            <span class="icon-bar"></span>
          </button>
        </div>
        <div class="navbar-collapse collapse" id="navbar-main">
          <ul class="nav navbar-nav">
            <li>
              <a href="#intro">Overview</a>
            </li>
            <li>
              <a href="#call">Call for papers</a>
            </li>
            <li>
              <a href="#schedule">Schedule</a>
            </li>
            <li>
              <a href="#speakers">Invited Speakers</a>
            </li>
            <li>
              <a href="#organizers">Organizers</a>
            </li>
          </ul>
          <ul class="nav navbar-nav navbar-right">
          </ul>
        </div>
      </div>
    </div>


    <div class="container">
      <div class="page-content">
          <div class="row" style="margin-top:30px;" id="intro">
            <div class="col-xs-12">
              <h1 style="text-align:center">Theories, Applications, and Cross Modality for <br> Self-Supervised Learning Models</h1>
              <h1 style="text-align:center">ICPR 2022 Workshop</h1>
            </div>
            <div class="col-xs-12">
              <br />
              <h1>Workshop Overview</h1>
              <p>
                Self-supervised learning has recently seen remarkable processes across various domains.
                The goal of SSL method is to learn useful semantic features without any human annotations. 
                In the absence of human-defined labels, the deep network is expected to learn richer feature structures explained by the data itself.
                There are many works across different modalities showing the empirical success of the SSL learning approaches.
                However, many questions are still lingering: is it possible to view self-supervised learning across different modalities in a unifying view?
                Is it possible to find the inherent connection between successful vision architectures and NLP architectures?
                How to interpret these connections?
                What mechanism essentially matters during the SSL feature learning procedure when we change data modalities?
              </p>
              <p>
                There are recently some emerging works starting to pay attention to these issues.
                However, the complete answer to the above questions still remains elusive and challenging.
                This workshop aims to approach the mysteries behind SSL from both theoretical and practical perspectives.
                We expect to invite experts from different communities and share their thoughts on how self-supervised learning approaches across different domains are connected and how they can potentially improve each other.
              </p>  
            </div>
          </div>

          <div class="row">
            <div class="col-xs-12">
              <h2>Topics Covered:</h2>
            </div>
          </div>
          <div class="row">
            <div class="col-xs-12">
              <ul>
                <li>
                  Theories of SSL models
                </li>
                <li>
                  SSL for computer vision tasks
                </li>
                <li>
                  SSL for NLP tasks
                </li>
                <li>
                  SSL for time series
                </li>
                <li>
                  SSL for graph models
                </li>
                <li>
                  Deep architecture design for SSL tasks
                </li>
                <li>
                  Cross modality models for SSL approaches
                </li>
                <li>
                  Other relevant SSL topics
                </li>
              </ul>
            </div>
          </div>
          <hr />

          <div class="row">
            <div class="col-xs-12" id="call">
              <h1>Call for papers</h1>
            </div>
          </div>

          <p><br /></p>

          <div class="row" id="dates">
            <div class="col-xs-12">
              <h2>Important Dates</h2>
            </div>
          </div>
          <div class="row">
            <div class="col-xs-12">
              <ul>
                <li>
                  <span style="font-weight:900;">Workshop paper submission deadline: <span style="color:grey"><strike>May 15, 2022, 03:00 pm Pacific Time</strike></span> <span style="color:red">May 31, 2022, 03:00 pm Pacific Time</span>.</span>
                </li>
                <li>
                  <span style="font-weight:900;">Notification to authors: <span style="color:grey"><strike>May 23, 2022, 03:00 pm Pacific Time</strike></span> <span style="color:red">June 6, 2022, 03:00 pm Pacific Time</span>.</span>
                </li>
                <li>
                  <span style="font-weight:900;">Camera-ready deadline: <span style="color:red">June 21, 2022, 03:00 pm Pacific Time</span>.</span>
                </li>
              </ul>
              <span style="font-weight:600;">Note: </span><span>In case of rejection from ICPR main conference, authors can submit their work to our SSL workshop by <span style="font-weight:900;color:red">May 31, 2022</span>. Authors should address all ICPR reviewers' comments in the submitted paper and submit the ICPR reviews as supplementary material.</span>
            </div>
            
          </div>


          <p><br /></p>
          <div class="row" id="dates">
            <div class="col-xs-12">
              <h2>Submission instructions</h2>
            </div>
          </div>
          <div class="row">
            <div class="col-xs-12">
              <p>
                We are following the ICPR 2022 paper format: <a href="https://www.icpr2022.com/submission-guidelines/" style="font-weight:600; color:steelblue;">https://www.icpr2022.com/submission-guidelines/</a>.
              </p>
              <p>
                LaTeX/Word Templates: <a href="https://www.google.com/url?q=https%3A%2F%2Fwww.icpr2022.com%2Fwp-content%2Fuploads%2F2021%2F11%2FIEEEconf_ICPR2022.zip&sa=D&sntz=1&usg=AOvVaw2qIVeB2KwLnbc--viOuv8W" style="font-weight:600; color:steelblue;">LaTeX</a> <span style="font-weight: 600;"> / </span> <a href="https://www.google.com/url?q=https%3A%2F%2Fwww.icpr2022.com%2Fwp-content%2Fuploads%2F2021%2F11%2FIEEEconf_ICPR2022.doc&sa=D&sntz=1&usg=AOvVaw3BO03oTZWuGPyqsq6impFQ" style="font-weight:600; color:steelblue;">Word</a>.
              </p>
              <p>
                All papers will be reviewed by at least two reviewers with single-blind peer review policy. Papers will be selected based on relevance, significance and novelty of results, technical merit, and clarity of presentation. Papers will be published in ICPR proceedings. 
              </p>
            </div>
          </div>

          <p><br /></p>
          <div class="row" id="dates">
            <div class="col-xs-12">
              <h2>Submission website</h2>
            </div>
          </div>
          <div class="row">
            <div class="col-xs-12">
              <p>
                Please submit your papers through <a href="https://cmt3.research.microsoft.com/SSL2022" style="font-weight:600; color:steelblue;">https://cmt3.research.microsoft.com/SSL2022</a>.
              </p>
            </div>
          </div>

          <p><br /></p>
          <hr />


          <div class="row" id="schedule">
            <div class="col-xs-12">
              <h1>Schedule (Eastern Standard Time Zone)</h1>
            </div>
          </div>
          <div class="row">
            <div class="col-xs-12">
              <table class="table table-striped">
                <tbody>
                  <tr>
                    <td>Initial greetings from the organizing committee</td>
                    <td>9:00 - 9:05</td>
                  </tr>
                  <tr>
                    <td>Invited Talk (<strong>Prof. Tengyu Ma</strong>, Stanford University)</td>
                    <td>9:05 - 9:40</td>
                  </tr>
                  <tr>
                    <td>Invited Talk (<strong>Dr. Yue Cao</strong>, Beijing Academy of Artificial Intelligence)</td>
                    <td>9:40 - 10:15</td>
                  </tr>
                  <tr>
                    <td>Invited Talk (<strong>Prof. Zuxuan Wu</strong>, Fudan University)</td>
                    <td>10:15 - 10:50</td>
                  </tr>
                  <tr>
                    <td>Invited Talk (<strong>Dr. Antoine Miech</strong>, DeepMind)</td>
                    <td>10:50 - 11:25</td>
                  </tr>
                  <tr>
                    <td>Coffee Break</td>
                    <td>11:25 - 11:35</td>
                  </tr>
                  <tr>
                    <td>Oral presentations (<strong style="font-size: small;">Joint Masked Autoencoding with Global Reconstruction for Point Cloud Learning</strong>)</td>
                    <td>11:35 - 11:50</td>
                  </tr>
                  <tr>
                    <td>Oral presentations (<strong style="font-size: small;">Enhancing the Linear Probing Performance of Masked Auto-Encoders</strong>)</td>
                    <td>11:50 - 12:05</td>
                  </tr>
                  <tr>
                    <td>Oral presentations (<strong style="font-size: small;">Involving Density Prior for 3D Point Cloud Contrastive Learning</strong>)</td>
                    <td>12:05 - 12:20</td>
                  </tr>
                  <tr>
                    <td>Oral presentations (<strong style="font-size: small;">Understanding the properties and limitations of contrastive learning for Out-of-Distribution detection</strong>)</td>
                    <td>12:20 - 12:35</td>
                  </tr>
                  <tr>
                    <td>Closing remarks</td>
                    <td>12:35 - </td>
                  </tr>
                </tbody>
              </table>
            </div>
          </div>

          <hr />


        <div class="row" id="speakers">
          <div class="col-xs-12">
            <h2>Invited Speakers</h2>
          </div>
          <div class="row">
            <div class="col-md-2">
              <a href="https://ai.stanford.edu/~tengyuma/"><img class="people-pic" style="float:left;margin-right:50px;" src="./static/img/speakers/Tengyu_Ma.jpeg" /></a>
            </div>
            <div class="col-md-10">
              <p>
                <b><a href="https://ai.stanford.edu/~tengyuma/">Tengyu Ma</a></b> is an assistant professor of computer science and statistics at the Stanford University.
                His research interests broadly include topics in machine learning and algorithms, such as deep learning and its theory, (deep) reinforcement learning and
                its theory, representation learning, robustness, non-convex optimization, distributed optimization, and high-dimensional statistics. Dr. Ma has been
                awarded ACM Doctoral Dissertation Award Honorable Mention 2018, COLT Best Paper Award 2018, and NIPS Best Student Paper Award 2016. He received his PhD
                from Princeton University in 2017.
              </p>
            </div>
          </div>

          <div class="row">
            <div class="col-md-2">
              <a href="http://yue-cao.me/"><img class="people-pic" style="float:left;margin-right:50px;" src="./static/img/speakers/Yue_Cao.png" /></a>
            </div>
            <div class="col-md-10">
              <p>
                <b><a href="http://yue-cao.me/">Yue Cao</a></b> is currently a researcher in Beijing Academy of Artificial Intelligence (BAAI). Prior to that, he was a senior
                researcher at Microsoft Research Asia between 2019 and 2022, headed by Baining Guo and closely collaborated with Han Hu, Zheng Zhang and Steve Lin. He received
                the Bachelor's and Doctor's degrees from the School of Software of Tsinghua University in 2014 and 2019, respectively, supervised by Prof. Jianmin Wang and
                Prof. Mingsheng Long. He was awarded Microsoft Ph.D. Scholarship in 2017 and Top Scholarship of Tsinghua University in 2018. His work of Swin Transformer won
                the Best Paper Award (Marr Prize) of ICCV 2021, and four of his research papers are included in the PaperDigest Most Influential Paper List. His papers have
                received more than 11000 citations in Google Scholar. His recent research interest includes foundation model, self-supervised learning and multimodal learning.
              </p>
            </div>
          </div>

          <div class="row">
            <div class="col-md-2">
              <a href="https://zxwu.azurewebsites.net/"><img class="people-pic" style="float:left;margin-right:50px;" src="./static/img/speakers/Zuxuan_Wu.png" /></a>
            </div>
            <div class="col-md-10">
              <p>
                <b><a href="https://zxwu.azurewebsites.net/">Zuxuan Wu</a></b> received his Ph.D. in Computer Science from the University of Maryland with Prof. Larry Davis
                in 2020. He is currently an Associate Professor in the School of Computer Science at Fudan University. His research interests are in computer vision and deep
                learning. His work has been recognized by an AI 2000 Most Influential Scholars Award in 2022, a Microsoft Research PhD Fellowship (10 people Worldwide) in
                2019 and a Snap PhD Fellowship (10 people Worldwide) in 2017.
              </p>
            </div>
          </div>
          <p><br /></p>


          <div class="row">
            <div class="col-md-2">
              <a href="https://antoine77340.github.io/"><img class="people-pic" style="float:left;margin-right:50px;" src="./static/img/speakers/Antoine_Miech.png" /></a>
            </div>
            <div class="col-md-10">
              <p>
                <b><a href="https://antoine77340.github.io/">Antoine Miech</a></b> is a Research Scientist working in DeepMind’s vision group. He completed his computer
                vision Ph.D. in the WILLOW project-team which is part of Inria and Ecole Normale Superieure, working with Ivan Laptev and Josef Sivic. His main research
                interests are video understanding and weakly-supervised machine learning. More generally, he is interested in everything related to Computer Vision,
                Machine Learning and Natural Language Processing. During the 2018 summer, he collaborated with Du Tran, Heng Wang and Lorenzo Torresani at Facebook AI.
                He was also awarded the Google Ph.D. fellowship in 2018.
              </p>
            </div>
          </div>
          <p><br /></p>
        </div>

        <hr />

        <div class="row" id="organizers">
          <div class="col-xs-12">
            <h2>Organizers</h2>
          </div>
        </div>

        <div class="row">
          <div class="col-xs-3">
            <a href="http://www.yuwangfeather.com">
              <img class="people-pic" src="./static/img/organizers/YuWang.png" />
            </a>
            <div class="people-name">
              <a href="http://www.yuwangfeather.com">Yu Wang</a>
              <h6>JD AI Research</h6>
            </div>
          </div>

          <div class="col-xs-3">
            <a href="http://home.ustc.edu.cn/~panywei/">
              <img class="people-pic" src="./static/img/organizers/Yingwei_Pan.png" />
            </a>
            <div class="people-name">
              <a href="http://home.ustc.edu.cn/~panywei/">Yingwei Pan</a>
              <h6>JD AI Research</h6>
            </div>
          </div>

          <div class="col-xs-3">
            <a href="https://profiles.ucsd.edu/jingjing.zou">
              <img class="people-pic" src="./static/img/organizers/JingjingZou.png" />
            </a>
            <div class="people-name">
              <a href="https://profiles.ucsd.edu/jingjing.zou">Jingjing Zou</a>
              <h6>University of California San Diego</h6>
            </div>
          </div>

          <div class="col-xs-3">
            <a href="https://angelicaiaviles.wordpress.com">
              <img class="people-pic" src="./static/img/organizers/angelicaiaviles.png" />
            </a>
            <div class="people-name">
              <a href="https://angelicaiaviles.wordpress.com">Angelica I. Aviles-Rivero</a>
              <h6>University of Cambridge</h6>
            </div>
          </div>
        </div>


        <div class="row">
          <div class="col-xs-3">
            <a href="http://www.damtp.cam.ac.uk/user/cbs31/Home.html">
              <img class="people-pic" src="./static/img/organizers/Carola-Bibiane.png" />
            </a>
            <div class="people-name">
              <a href="http://www.damtp.cam.ac.uk/user/cbs31/Home.html">Carola-Bibiane Schönlieb</a>
              <h6>University of Cambridge</h6>
            </div>
          </div>

          <div class="col-xs-3">
            <a href="http://www.statslab.cam.ac.uk/~jada2/">
              <img class="people-pic" src="./static/img/organizers/John_Aston.png" />
            </a>
            <div class="people-name">
              <a href="http://www.statslab.cam.ac.uk/~jada2/">John Aston</a>
              <h6>University of Cambridge</h6>
            </div>
          </div>

          <div class="col-xs-3">
            <a href="http://tingyao.deepfun.club">
              <img class="people-pic" src="./static/img/organizers/Ting_Yao.png" />
            </a>
            <div class="people-name">
              <a href="http://tingyao.deepfun.club">Ting Yao</a>
              <h6>JD AI Research</h6>
            </div>
          </div>
        </div>

        <p><br /></p>


        <div class="row" id="contact">
          <div class="col-xs-12">
            <h2>Contact</h2>
          </div>
        </div>
        <div class="row">
          <div class="col-xs-12">
            <p>
              To contact the organizers please use <b>icpr2022.ssl@gmail.com</b>
            </p>
          </div>
        </div>
        <p><br /></p>

        <hr />

        <p><a class="anchor" name="/acknowledgements"></a></p>
        <div class="row">
          <div class="col-xs-12">
            <h2>Acknowledgements</h2>
          </div>
        </div>
        <div class="row">
          <div class="col-xs-12">
            <p>
              Thanks to <a href="https://visualdialog.org/">visualdialog.org</a> for the webpage format.
            </p>
          </div>
        </div>

      </div>
    </div>

    

    <!-- Google analytics -->
    <script data-cfasync="false" src="/cdn-cgi/scripts/5c5dd728/cloudflare-static/email-decode.min.js"></script><script>
      (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
      (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
      m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
      })(window,document,'script','https://www.google-analytics.com/analytics.js','ga');
      ga('create', 'UA-88406333-1', 'auto');
      ga('send', 'pageview');
    </script>

    <script type="text/javascript" src="./static/js/jquery.min.js"></script>
    <script type="text/javascript" src="./static/js/bootstrap.min.js"></script>

  </body>
</html>
